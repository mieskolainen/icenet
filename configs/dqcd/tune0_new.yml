# DQCD tune0.yml
#
# https://twiki.cern.ch/twiki/bin/view/CMSPublic/WorkBookNanoAOD

rootname: 'dqcd'
rngseed: 123456                       # Fixed seed for training data mixing
inputvars: 'mvavars_new'              # Main file input description python file

# ----------------------------------------------------
mva_param: &MVA_INPUT_PARAM
  use_conditional: false              # Conditional (theory parametric) input

  primary_classes: [0,1]              # Primary class IDs in MVA (train, ROC etc.)
  signal_class: 1                     # Signal class ID
  DA_class:    -2                     # Domain Adaptation class
  
  inputvar_scalar: 'MVA_SCALAR_VARS'  # Input variables, implemented under mvavars.py
  inputvar_jagged: 'MVA_JAGGED_VARS'
  
  # For xgboost etc. fixed input dimension models
  # The variable names below need to match the nanoAOD variable names, e.g. 'Jet_*'
  jagged_maxdim:
    
    Jet:  6
    Muon: 10
    muonSV: 12
    SV:   6
    cpf:  0     # 20
    npf:  0     # 10
  
  
  # Filtering of collection entries (for BDT)
  jagged_filter:
    
    - name: 'muonSV'
      condition: 'muonSV.dlen > 0'   # placeholder, for 'muonSV.charge == 0' condition

  # Re-ordering of collection entries (for BDT)
  jagged_order:

    - name: 'muonSV'
      var:  'chi2'
      ascending: True  # True ~ smallest first, False ~ largest first
    
    - name: 'SV'
      var:  'dlen'
      ascending: False
    
    - name: 'Jet'
      var:  'pt'   
      ascending: False
    
    - name: 'Muon'
      var:  'pt'   
      ascending: False
    
    # add more here ..

  frac: [0.6, 0.1, 0.3]              # Train vs validate/test split fraction
  
  # Variable imputation
  imputation_param:
    active: true                     # True / False
    var: null                        # Array of variables to be imputated, if null, then all
    algorithm: 'constant'            # Algorithm type: 'constant', iterative' (vector), knn' (vector), 'mean' (scalar), 'median' (scalar)
    fill_value: -999.0               # For constant imputation
    knn_k: 8                         # Number of nearest neighbours considered
    values: null                     # Special values which indicate the need for imputation, if null, then only Inf/Nan/Empty
  
  varnorm: null                      # Variable normalization: 'zscore', 'madscore', null
  #varnorm_tensor: 'zscore'          # Tensor variable normalization
  #varnorm_graph: null               # Not implemented yet
  
  # Graph object construction
  graph_param:
    global_on: True
    self_loops: True
    directed: False
    coord: 'pxpypze'                 # 'ptetaphim', 'pxpypze'

  # ** Image tensor object construction **
  image_param:

    # See the corresponding construction under common.py
    channels: 2                 # 1,2,...
    
    # bin-edges
    eta_bins: []
    phi_bins: []
      

# ----------------------------------------------------
genesis_runmode:
  
  maxevents:  null
  inputmap:  "mc_input.yml"
  tree_name:  null #'ntuplizer/tree'
  
  filterfunc: 'filter_standard'      # Filter cuts, implemented under filter.py
  cutfunc:    'cut_fiducial'         # Basic cuts,  implemented under cuts.py
  targetfunc:  null                  # -- not active --
  
  xcorr_flow: True                   # Full N-point correlations computed between cuts
  pickle_size: 1000                  # Number of entries (events) per pickle file


# ----------------------------------------------------
train_runmode:

  <<: *MVA_INPUT_PARAM

  maxevents: null
  modeltag:  null
  
  # Conditional (theory parametric) dequantization
  conditional_param:
    dequantize_common: True           # Under common.py
    dequantize_batch:  False          # (mini)batch based training (reservation)
    n_interp:   1000                  # Number of interpolation points per dimension
    kind:       'quadratic'           # Interpolator ('linear', 'quadratic', 'cubic' ...),
                                      # see scipy.interpolate.interp1d
  
  ## Reweighting setup
  reweight: true
  reweight_mode: 'write'              # 'write', 'load'
  reweight_file: 'reweight_train.pkl' # differential reweighting model file
  
  reweight_param: &REWEIGHT_PARAM
    
    maxevents: 1000000             # Maximum number of events for the PDF construction
    equal_frac: True               # Equalize integrated class fractions
    differential: False
    reference_class: 0             # Reference class: 0 = (background), 1 = (signal), 2 = (another class) ..., 
    
    # see /trg/tune0.yml


  ## Outlier protection in the training
  outlier_param:
    algo: 'truncate'   # algorithm: 'truncate', null
    qmin: 0.01         # in [0,100] 
    qmax: 99.9         # in [0,100]
  

  # ** Activate models here **
  # Give all models some unique identifier and label
  models:  !include configs/dqcd/models.yml
  active_models: &ACTIVE_MODELS
    
    #- gnet2
    #- gnet1
    #- gnet3
    
    - iceboost01-DA
    - iceboost01-DA-NOJETS
    - iceboost01-DA-MI
    - iceboost01-DA-MI-NOJETS
    - xgb01
    
    #- xgb01-NOJETS
    #- iceboost01-DA-NC
    
    #- xgb01-no-mass
    #- xgb01-no-jets
    
    #- dmlp
    #- lgr0
    
    #- deps
    #- vae0    
    #- dbnf0
    
    #- xgb1
    #- dmlp
    #- dmx0
    #- dmx1
    
    #- exp
    #- cut0
    #- cut1
    #- cut2
    #- cutset0
  
  raytune: !include configs/dqcd/raytune.yml

  # Distillation training
  # -- the order must be compatible with the causal order in 'active_models'
  distillation:

    # Big, sophisticated model
    source:
      #xgb0
      
    # Simple, compressed models
    drains:
      #- xgb1
      # - add more here

  # Batched "deep" training
  batch_train_param:
    blocksize: 150000   # Maximum number of events simultaneously in RAM
    epochs: 50          # Number of global epochs (1 epoch = one iteration over the full input dataset), same for all models
    #num_cpu: null      # Set null for auto, or an integer for manual.

# ----------------------------------------------------
eval_runmode:
  
  <<: *MVA_INPUT_PARAM

  maxevents: null
  modeltag:  null
  
  # Conditional (theory parametric) dequantization
  conditional_param:
    dequantize_common: False           # Under common.py
    n_interp:   1000                  # Number of interpolation points per dimension
    kind:       'quadratic'              # Interpolator ('linear', 'quadratic', 'cubic' ...),
                                      # see scipy.interpolate.interp1d
  
  reweight: true
  reweight_mode: 'load'               # 'write', 'load'
  reweight_file: 'reweight_train.pkl'

  reweight_param: *REWEIGHT_PARAM

  models:  !include configs/dqcd/models.yml
  active_models: *ACTIVE_MODELS


# ----------------------------------------------------
optimize_runmode:
  
  <<: *MVA_INPUT_PARAM

  maxevents: null
  modeltag:  null

  reweight: true
  reweight_mode: 'load'               # 'write', 'load'
  reweight_file: 'reweight_train.pkl'

  reweight_param: *REWEIGHT_PARAM

  limits_param:
    luminosity: 41600         # pb^{-1}
    signal_xs:  44.0          # pb (reference xs), gg -> H https://twiki.cern.ch/twiki/bin/view/LHCPhysics/CERNYellowReportPageAt13TeV
    target_r:   0.01          # Benchmark branching ratio (BR)
    
    const_mode: 'bgk_eff'     # Which to keep constant, 'cut', 'bgk_eff'
    const_cut:     0.9        # Target cut value (--> FPR varies per signal point)
    const_bgk_eff: 1.0e-4     # Background efficiency (FPR) target after trigger & pre-cut (--> cut varies per signal point)
    commutate_BOX: True       # True if commutate BOX cut (with low MC stats), False if apply in physical order
    
    model_POI: ['mpi', 'mA', 'ctau'] # Theory (signal) model param-of-interest
    box_POI:   ['M', 'mA']           # (observable, theory) pair
    
    # Be very precise with these and which efficiencies need to book-keeped
    # (see definitions under plots.yml)
    GEN_filter_tag: 'F[0]'    # Theory param filter
    BOX_filter_tag: 'F[4]'    # Mass window filter
    GBX_filter_tag: 'F[3]'    # Theory param filter & mass window together
    
    channel_mode: 'inclusive' # 'inclusive', 'categorical' (not implemented)
    methods: ['asymptotic']   # ['asymptotic', 'toys']
    num_toys_obs: 10000       # Number of MC samples for 'toys'
    systematics: null
    
    # ** NOT IMPLEMENTED YET (only in tune0.yml) **
    brazil: null
    
    cosmetics:
      title:  '$41.6$ fb$^{-1}$, $\sqrt{{s}} = 13$ TeV'
      ylabel: '$r = \sigma_{gg \rightarrow H \rightarrow DQCD} \, / \sigma_{gg \rightarrow H}$'
      portal: 'scenario X (new)'
  
  models:  !include configs/dqcd/models.yml
  active_models: *ACTIVE_MODELS


# ----------------------------------------------------
deploy_runmode:
  
  <<: *MVA_INPUT_PARAM

  maxevents: null
  modeltag:  null
  
  mc_param: !include configs/dqcd/mc_param_new.yml
  
  models:  !include configs/dqcd/models.yml
  active_models: *ACTIVE_MODELS


# ----------------------------------------------------
plot_param: !include configs/dqcd/plots_new.yml
